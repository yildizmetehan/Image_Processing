{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yjFLAx-rBpeu"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Notebook içine gömülen görsellerin \"ağırlığını\" düşürür\n",
    "mpl.rcParams[\"figure.dpi\"] = 80\n",
    "mpl.rcParams[\"savefig.dpi\"] = 80\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Çok büyük figürleri otomatik sınırlamak için (opsiyonel)\n",
    "MAX_FIGSIZE = (12, 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDak4IWL4Ojj"
   },
   "source": [
    "**0.1 Kütüphaneler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VKEvXr814RNS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tz0pdUW4axK"
   },
   "source": [
    "**0.2 Veri Yolu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UtHuR4XY4cIF"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/content/drive/MyDrive/ISIC_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "m-b42Rc74g1w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0G-ityT5vzg"
   },
   "source": [
    "**1 - RGB → Grayscale Dönüşümü**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjd8Lveq6gO5"
   },
   "source": [
    "**RGB → Gray öncesi kıl bastırma fonksiyonu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qjeMpslk6k1p"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def hair_removal_rgb(img_rgb):\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(img_gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    _, mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    inpainted = cv2.inpaint(img_gray, mask, 1, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return inpainted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slbyzQDM6qpO"
   },
   "source": [
    "**1) RGB → Grayscale + Artefakt Bastırma (9 örnek)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lT6oN1uL6sS_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import random\n",
    "\n",
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "    gray_clean = hair_removal_rgb(rgb)\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(\"RGB (Orijinal)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.imshow(gray_clean, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale (Artefakt Bastırılmış)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMOy371m7Csd"
   },
   "source": [
    "**2 - Pre-Processing**\n",
    "\n",
    "**2.1 Crop**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBNYDHsO8No0"
   },
   "source": [
    "**Crop fonksiyonu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wwvK2CBP7Pp5"
   },
   "outputs": [],
   "source": [
    "def center_crop(img, crop_ratio=0.1):\n",
    "    h, w = img.shape[:2]\n",
    "    dh = int(h * crop_ratio)\n",
    "    dw = int(w * crop_ratio)\n",
    "    return img[dh:h-dh, dw:w-dw]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHkPyq-f8O09"
   },
   "source": [
    "**2.1 Crop – 9 örnek görselleştirme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sdeGoZgZ8Q1Q"
   },
   "outputs": [],
   "source": [
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "    gray_clean = hair_removal_rgb(rgb)\n",
    "    cropped = center_crop(gray_clean, crop_ratio=0.1)\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(gray_clean, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale (Crop Öncesi)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.imshow(cropped, cmap=\"gray\")\n",
    "    plt.title(\"Crop Sonrası\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLFyC7SP9Chi"
   },
   "source": [
    "**2.2 Kontrast İyileştirme**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME1t7_Kc9JdI"
   },
   "source": [
    "**Histogram Equalization uygulaması**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Bc96CxWO9Lmn"
   },
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def contrast_enhancement(img_gray):\n",
    "    img_eq = exposure.equalize_hist(img_gray)\n",
    "    return img_eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1NdfIYK9M_A"
   },
   "source": [
    "**9 örnek için görselleştirme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "q1wDDKN39O0w"
   },
   "outputs": [],
   "source": [
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "    gray_clean = hair_removal_rgb(rgb)\n",
    "    cropped = center_crop(gray_clean, crop_ratio=0.1)\n",
    "    enhanced = contrast_enhancement(cropped)\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(cropped, cmap=\"gray\")\n",
    "    plt.title(\"Crop Sonrası\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.imshow(enhanced, cmap=\"gray\")\n",
    "    plt.title(\"Histogram Equalization\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7qd9YC9-MiZ"
   },
   "source": [
    "**2.3 Gürültü Azaltma / Blurring**\n",
    "\n",
    "**2.3.1 Blur yöntemi seçimi: Median Blur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "z9OtS9TJ-T5P"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def denoise_blur(img_gray_float, ksize=5, method=\"median\"):\n",
    "    \"\"\"\n",
    "    img_gray_float: [0,1] aralığında float grayscale\n",
    "    return: [0,1] aralığında float grayscale\n",
    "    \"\"\"\n",
    "    img_u8 = (np.clip(img_gray_float, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    if method == \"median\":\n",
    "        # ksize tek sayı olmalı (3,5,7,...)\n",
    "        out_u8 = cv2.medianBlur(img_u8, ksize)\n",
    "    elif method == \"gaussian\":\n",
    "        out_u8 = cv2.GaussianBlur(img_u8, (ksize, ksize), 0)\n",
    "    else:\n",
    "        raise ValueError(\"method 'median' veya 'gaussian' olmalı\")\n",
    "\n",
    "    return out_u8.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvK2KDQQ-Vuz"
   },
   "source": [
    "**2.3.2 9 örnek: dönüşüm öncesi/sonrası görseller**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DV15HYWG-YB-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/pigmented benign keratosis/ISIC_0025466.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/nevus/ISIC_0000094.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/vascular lesion/ISIC_0032919.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma/ISIC_0026192.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma/ISIC_0031095.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma/ISIC_0027629.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/nevus/ISIC_0000416.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/squamous cell carcinoma/ISIC_0032397.jpg\n",
      "Processing image: /content/drive/MyDrive/ISIC_data/extracted/Skin cancer ISIC The International Skin Imaging Collaboration/Train/melanoma/ISIC_0010723.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    print(f\"Processing image: {p}\") # Added for debugging\n",
    "    rgb = imread(p)\n",
    "\n",
    "    # 1) Artefakt bastırma (çıktı uint8 grayscale)\n",
    "    gray_clean_u8 = hair_removal_rgb(rgb)              # uint8 [0,255]\n",
    "    gray_clean = gray_clean_u8.astype(np.float32) / 255.0  # float [0,1]\n",
    "\n",
    "    # 2) Crop\n",
    "    cropped = center_crop(gray_clean, crop_ratio=0.1)\n",
    "\n",
    "    # 3) Kontrast (Histogram Equalization)\n",
    "    enhanced = contrast_enhancement(cropped)           # skimage equalize_hist -> float [0,1]\n",
    "\n",
    "    # 4) Blur (Median)\n",
    "    blurred = denoise_blur(enhanced, ksize=5, method=\"median\")\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(enhanced, cmap=\"gray\")\n",
    "    plt.title(\"Kontrast Sonrası (Blur Öncesi)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.imshow(blurred, cmap=\"gray\")\n",
    "    plt.title(\"Median Blur (Sonrası)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMZK-Z8NAjq2"
   },
   "source": [
    "**3 - Thresholding ile Segmentasyon**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKQlfS0zA0xI"
   },
   "source": [
    "**3.0 Yardımcı: pipeline çıktısını üret (blurred görüntü)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mva8LUKJA3Bl"
   },
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def preprocess_to_blur(img_rgb):\n",
    "    # 1) Kıl bastırma (uint8 gray)\n",
    "    gray_u8 = hair_removal_rgb(img_rgb)\n",
    "    gray = gray_u8.astype(np.float32) / 255.0\n",
    "\n",
    "    # 2) Crop\n",
    "    cropped = center_crop(gray, crop_ratio=0.1)\n",
    "\n",
    "    # 3) Kontrast (Histogram Equalization)\n",
    "    enhanced = exposure.equalize_hist(cropped).astype(np.float32)\n",
    "\n",
    "    # 4) Blur (Median)\n",
    "    blurred = denoise_blur(enhanced, ksize=5, method=\"median\")\n",
    "    return blurred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLEnNONoA4eT"
   },
   "source": [
    "**3.1 Threshold değerlerini hesapla (Global + Otsu + Try-all’den 1 yöntem)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "stH1jM4PA6uv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.filters import threshold_otsu, threshold_yen, try_all_threshold\n",
    "\n",
    "def compute_thresholds(img_gray_float):\n",
    "    \"\"\"\n",
    "    img_gray_float: [0,1] float\n",
    "    \"\"\"\n",
    "    # Global threshold: sabit bir değer seçiyoruz (genelde 0.5 başlangıçtır)\n",
    "    # İstersen bunu histogramına bakıp 0.45/0.55 gibi ayarlayabiliriz.\n",
    "    t_global = 0.5\n",
    "\n",
    "    # Otsu: otomatik eşik\n",
    "    t_otsu = float(threshold_otsu(img_gray_float))\n",
    "\n",
    "    # try_all_threshold içinden bir yöntem seçiyoruz: örnek olarak Yen (otomatik)\n",
    "    # (try_all_threshold görselleştirme içindir; burada seçtiğimiz yöntemin eşik değerini raporluyoruz)\n",
    "    t_yen = float(threshold_yen(img_gray_float))\n",
    "\n",
    "    return {\n",
    "        \"Global\": t_global,\n",
    "        \"Otsu\": t_otsu,\n",
    "        \"Yen (try_all seçimi)\": t_yen\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XafscxQkA8L7"
   },
   "source": [
    "**3.1 Çıktı: 9 örnek için eşik değerlerini print + tablo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8ZhTIC50A-G7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eşik değerleri (9 örnek):\n",
      "   Global_T    Otsu_T     Yen_T\n",
      "0       0.5  0.480530  0.620604\n",
      "1       0.5  0.480530  0.142019\n",
      "2       0.5  0.472748  0.313220\n",
      "3       0.5  0.453294  0.180928\n",
      "4       0.5  0.449403  0.130346\n",
      "5       0.5  0.499985  0.484421\n",
      "6       0.5  0.492203  0.745113\n",
      "7       0.5  0.472748  0.149801\n",
      "8       0.5  0.499985  0.258747\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from skimage.io import imread\n",
    "\n",
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "rows = []\n",
    "for p in sample_paths:\n",
    "    rgb = imread(p)\n",
    "    blurred = preprocess_to_blur(rgb)\n",
    "    ths = compute_thresholds(blurred)\n",
    "\n",
    "    rows.append({\n",
    "        \"image_path\": p,\n",
    "        \"Global_T\": ths[\"Global\"],\n",
    "        \"Otsu_T\": ths[\"Otsu\"],\n",
    "        \"Yen_T\": ths[\"Yen (try_all seçimi)\"]\n",
    "    })\n",
    "\n",
    "thr_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Eşik değerleri (9 örnek):\")\n",
    "print(thr_df[[\"Global_T\", \"Otsu_T\", \"Yen_T\"]])\n",
    "\n",
    "thr_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRFZ5iXaBC6y"
   },
   "source": [
    "3.2 Binary maskeleri üret + 9 örnekte karşılaştırmalı görselleştir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QQagFvfPBICt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_threshold(img_gray_float, t):\n",
    "    # Lezyon genelde daha koyu olabilir; hangi tarafın lezyon olduğuna göre tersine çevirebiliriz.\n",
    "    # Başlangıç olarak: img < t -> lezyon (1)\n",
    "    return (img_gray_float < t).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(16, 24))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "    blurred = preprocess_to_blur(rgb)\n",
    "    ths = compute_thresholds(blurred)\n",
    "\n",
    "    mask_global = apply_threshold(blurred, ths[\"Global\"])\n",
    "    mask_otsu   = apply_threshold(blurred, ths[\"Otsu\"])\n",
    "    mask_yen    = apply_threshold(blurred, ths[\"Yen (try_all seçimi)\"])\n",
    "\n",
    "    # 4 sütun: giriş + 3 maske\n",
    "    plt.subplot(9, 4, 4*i+1)\n",
    "    plt.imshow(blurred, cmap=\"gray\")\n",
    "    plt.title(\"Preprocessed (Blur Sonrası)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 4, 4*i+2)\n",
    "    plt.imshow(mask_global, cmap=\"gray\")\n",
    "    plt.title(f\"Global (T={ths['Global']:.3f})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 4, 4*i+3)\n",
    "    plt.imshow(mask_otsu, cmap=\"gray\")\n",
    "    plt.title(f\"Otsu (T={ths['Otsu']:.3f})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 4, 4*i+4)\n",
    "    plt.imshow(mask_yen, cmap=\"gray\")\n",
    "    plt.title(f\"Yen (T={ths['Yen (try_all seçimi)']:.3f})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjoO43fTCa9e"
   },
   "source": [
    "**try_all_threshold’i 1 örnekte gösterme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IxAbY69QCYH_"
   },
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "rgb = imread(sample_paths[0])\n",
    "blurred = preprocess_to_blur(rgb)\n",
    "\n",
    "fig, ax = try_all_threshold(blurred, figsize=(10, 8), verbose=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZQyE3NvEFss"
   },
   "source": [
    "**4 - Post-Processing**\n",
    "\n",
    "**4.1 Morfolojik Operatörler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LypF8krrElRW"
   },
   "outputs": [],
   "source": [
    "def morph_postprocess_safe(mask_bin, ksize_close=5):\n",
    "    \"\"\"\n",
    "    Güvenli post-processing:\n",
    "    - SADECE closing\n",
    "    - küçük kernel\n",
    "    - ROI tamamen silinirse geri al\n",
    "    \"\"\"\n",
    "    m = (mask_bin * 255).astype(np.uint8)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (ksize_close, ksize_close)\n",
    "    )\n",
    "\n",
    "    closed = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Güvenlik: eğer ROI yok olduysa orijinale dön\n",
    "    if np.sum(closed) == 0:\n",
    "        closed = m.copy()\n",
    "\n",
    "    return (closed > 0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EFD4I73ENFx"
   },
   "source": [
    "**9 örnek: giriş maske + morfoloji sonrası**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "kjZqXGMiEnPf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "    _, t, mask_otsu = otsu_mask_from_rgb(rgb)\n",
    "\n",
    "    mask_morph = morph_postprocess_safe(mask_otsu, ksize_close=5)\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(mask_otsu, cmap=\"gray\")\n",
    "    plt.title(f\"Giriş Maske (Otsu T={t:.3f})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.imshow(mask_morph, cmap=\"gray\")\n",
    "    plt.title(\"Morfoloji Sonrası (Closing)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpKxRypxHgVB"
   },
   "source": [
    "**4.2 Connected Component Labeling (CCL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUbnYBv4Hjn5"
   },
   "source": [
    "**4.2.0 — Yardımcı fonksiyonlar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-QoDCV_WHlnB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def connected_components(mask_bin):\n",
    "    \"\"\"\n",
    "    mask_bin: 0/1 uint8\n",
    "    return: num_labels (bg dahil), labels, fg_count (bg hariç)\n",
    "    \"\"\"\n",
    "    num_labels, labels = cv2.connectedComponents(mask_bin.astype(np.uint8))\n",
    "    fg_count = num_labels - 1\n",
    "    return num_labels, labels, fg_count\n",
    "\n",
    "def labels_to_color(labels):\n",
    "    \"\"\"CCL label haritasını renkli görselleştirir.\"\"\"\n",
    "    if labels.max() == 0:\n",
    "        return np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "    lab_u8 = (labels.astype(np.float32) / labels.max() * 255).astype(np.uint8)\n",
    "    colored = cv2.applyColorMap(lab_u8, cv2.COLORMAP_JET)\n",
    "    colored = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)\n",
    "    return colored\n",
    "\n",
    "def remove_small_components(mask_bin, min_area=500):\n",
    "    \"\"\"Küçük bağlı bileşenleri (gürültü) eler.\"\"\"\n",
    "    num, lab = cv2.connectedComponents(mask_bin.astype(np.uint8))\n",
    "    out = np.zeros_like(mask_bin, dtype=np.uint8)\n",
    "    for k in range(1, num):\n",
    "        area = int(np.sum(lab == k))\n",
    "        if area >= min_area:\n",
    "            out[lab == k] = 1\n",
    "    return out\n",
    "\n",
    "def keep_largest_component(mask_bin):\n",
    "    \"\"\"En büyük alanlı bağlı bileşeni seçer.\"\"\"\n",
    "    num, lab = cv2.connectedComponents(mask_bin.astype(np.uint8))\n",
    "    if num <= 2:  # bg + 1 fg\n",
    "        return mask_bin\n",
    "\n",
    "    areas = []\n",
    "    for k in range(1, num):\n",
    "        areas.append((k, int(np.sum(lab == k))))\n",
    "    largest = max(areas, key=lambda x: x[1])[0]\n",
    "    return (lab == largest).astype(np.uint8)\n",
    "\n",
    "def pick_single_roi(mask_bin, min_area=500):\n",
    "    \"\"\"\n",
    "    1 görüntü = 1 ROI stratejisi:\n",
    "    1) küçük bileşenleri ele (alan filtresi)\n",
    "    2) en büyük bileşeni ROI olarak seç\n",
    "    3) ROI çok küçük kalırsa maskeyi invert edip tekrar dene (lezyon/arka plan tersliği için)\n",
    "    \"\"\"\n",
    "    cleaned = remove_small_components(mask_bin, min_area=min_area)\n",
    "    roi = keep_largest_component(cleaned)\n",
    "\n",
    "    # güvenlik: ROI çok küçükse tersini dene\n",
    "    if np.sum(roi) < 1000:\n",
    "        inv = 1 - mask_bin\n",
    "        cleaned2 = remove_small_components(inv, min_area=min_area)\n",
    "        roi2 = keep_largest_component(cleaned2)\n",
    "        if np.sum(roi2) > np.sum(roi):\n",
    "            roi = roi2\n",
    "\n",
    "    return roi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trZMReo4HqKY"
   },
   "source": [
    "**4.2.1 — 9 örnek: bileşen sayısını çizdir + renkli label plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Nn-O-LUcIMje"
   },
   "outputs": [],
   "source": [
    "sample_paths = random.sample(image_paths, 9)\n",
    "\n",
    "component_counts_plot = []\n",
    "\n",
    "plt.figure(figsize=(14, 18))\n",
    "\n",
    "for i, p in enumerate(sample_paths):\n",
    "    rgb = imread(p)\n",
    "\n",
    "    # 4.1 çıktısı\n",
    "    _, _, mask_otsu = otsu_mask_from_rgb(rgb)\n",
    "    mask_morph = morph_postprocess_safe(mask_otsu, ksize_close=5)\n",
    "\n",
    "    # CCL\n",
    "    _, labels_before, fg_before = connected_components(mask_morph)\n",
    "    component_counts_plot.append(fg_before)\n",
    "\n",
    "    # Renkli label\n",
    "    colored = labels_to_color(labels_before)\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+1)\n",
    "    plt.imshow(colored)\n",
    "    plt.title(f\"CCL Label (fg={fg_before})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(9, 2, 2*i+2)\n",
    "    plt.bar([\"Bileşen Sayısı\"], [fg_before])\n",
    "    plt.ylim(0, max(component_counts_plot) + 5)\n",
    "    plt.title(\"Bileşen Sayısı (bg hariç)\")\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR-dSKANJC2r"
   },
   "source": [
    "**5 - Öznitelik (Feature) Çıkarımı**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoCa6LMoJYFH"
   },
   "source": [
    "**5.1 First-Order (İstatistiksel) Özellikler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CqKp3CA4JZ4C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def first_order_features(gray_img, roi_mask):\n",
    "    pixels = gray_img[roi_mask == 1]\n",
    "\n",
    "    feats = {}\n",
    "    feats[\"mean\"] = float(np.mean(pixels))\n",
    "    feats[\"std\"] = float(np.std(pixels))\n",
    "    feats[\"variance\"] = float(np.var(pixels))\n",
    "    feats[\"min\"] = float(np.min(pixels))\n",
    "    feats[\"max\"] = float(np.max(pixels))\n",
    "    feats[\"median\"] = float(np.median(pixels))\n",
    "    feats[\"skewness\"] = float(skew(pixels))\n",
    "    feats[\"kurtosis\"] = float(kurtosis(pixels))\n",
    "\n",
    "    # Entropy\n",
    "    hist, _ = np.histogram(pixels, bins=256, density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    feats[\"entropy\"] = float(-np.sum(hist * np.log2(hist)))\n",
    "\n",
    "    # Energy\n",
    "    feats[\"energy\"] = float(np.sum(pixels ** 2))\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5I96CtzJbkL"
   },
   "source": [
    "**5.2 2D Shape (Şekil) Özellikleri**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "H4jpR7GwJgDJ"
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops, label\n",
    "\n",
    "def shape_features(roi_mask):\n",
    "    lbl = label(roi_mask)\n",
    "    props = regionprops(lbl)[0]   # 1 ROI varsayımı\n",
    "\n",
    "    feats = {}\n",
    "    feats[\"area\"] = props.area\n",
    "    feats[\"perimeter\"] = props.perimeter\n",
    "    feats[\"eccentricity\"] = props.eccentricity\n",
    "    feats[\"solidity\"] = props.solidity\n",
    "    feats[\"extent\"] = props.extent\n",
    "\n",
    "    feats[\"major_axis_length\"] = props.major_axis_length\n",
    "    feats[\"minor_axis_length\"] = props.minor_axis_length\n",
    "    feats[\"aspect_ratio\"] = props.major_axis_length / props.minor_axis_length\n",
    "\n",
    "    feats[\"convex_area\"] = props.convex_area\n",
    "    feats[\"equivalent_diameter\"] = props.equivalent_diameter\n",
    "\n",
    "    # Circularity\n",
    "    feats[\"circularity\"] = (4 * np.pi * props.area) / (props.perimeter ** 2)\n",
    "\n",
    "    # Bounding box\n",
    "    minr, minc, maxr, maxc = props.bbox\n",
    "    feats[\"bbox_width\"] = maxc - minc\n",
    "    feats[\"bbox_height\"] = maxr - minr\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1sIclcaJiN0"
   },
   "source": [
    "**5.3 GLCM (Second-Order Texture) Özellikleri**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "WQ8xGhXaJopL"
   },
   "outputs": [],
   "source": [
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "def glcm_features(gray_img, roi_mask,\n",
    "                  distances=[1, 2],\n",
    "                  angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                  levels=16):\n",
    "\n",
    "    # ROI dışını maskele\n",
    "    masked = gray_img.copy()\n",
    "    masked[roi_mask == 0] = 0\n",
    "\n",
    "    # Quantization\n",
    "    img_q = np.floor(masked * (levels - 1)).astype(np.uint8)\n",
    "\n",
    "    glcm = graycomatrix(\n",
    "        img_q,\n",
    "        distances=distances,\n",
    "        angles=angles,\n",
    "        levels=levels,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    feats = {}\n",
    "    for prop in [\"contrast\", \"dissimilarity\", \"homogeneity\",\n",
    "                 \"energy\", \"correlation\", \"ASM\"]:\n",
    "        feats[f\"glcm_{prop}\"] = float(np.mean(graycoprops(glcm, prop)))\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AM63gcmJp91"
   },
   "source": [
    "**5.4 Feature Tablosu (CSV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "j-OTm2R5VIYh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GLCM Parametreleri: levels= 8 distances= [1] angles= [0, 1.5707963267948966] patch= 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bitti.\n",
      "Toplam görüntü (liste): 2357\n",
      "İşlenen satır (ROI) sayısı: 2356\n",
      "Feature sütun sayısı: 31\n",
      "Atlanan (okunamayan) dosya: 1\n",
      "CSV: lesion_features.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total number of columns (31) exceeds max_columns (20) limiting to first (20) columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.io import imread\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "\n",
    "MIN_AREA = 500\n",
    "GLCM_LEVELS = 8\n",
    "GLCM_DISTANCES = [1]\n",
    "GLCM_ANGLES = [0, np.pi/2]\n",
    "GLCM_PATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def safe_imread(path):\n",
    "    try:\n",
    "        x = imread(path)\n",
    "        return x if x is not None else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def crop_to_roi_patch(gray_img, roi_mask, patch_size=GLCM_PATCH_SIZE):\n",
    "    props = regionprops(label(roi_mask))\n",
    "    if len(props) == 0:\n",
    "        return None, None\n",
    "\n",
    "    cy, cx = map(int, props[0].centroid)\n",
    "    half = patch_size // 2\n",
    "\n",
    "    y1 = max(cy - half, 0)\n",
    "    y2 = min(cy + half, gray_img.shape[0])\n",
    "    x1 = max(cx - half, 0)\n",
    "    x2 = min(cx + half, gray_img.shape[1])\n",
    "\n",
    "    g = gray_img[y1:y2, x1:x2]\n",
    "    m = roi_mask[y1:y2, x1:x2].astype(np.uint8)\n",
    "\n",
    "    # patch boyutu tutmazsa padding\n",
    "    if g.shape[0] != patch_size or g.shape[1] != patch_size:\n",
    "        g_pad = np.zeros((patch_size, patch_size), dtype=g.dtype)\n",
    "        m_pad = np.zeros((patch_size, patch_size), dtype=m.dtype)\n",
    "        g_pad[:g.shape[0], :g.shape[1]] = g\n",
    "        m_pad[:m.shape[0], :m.shape[1]] = m\n",
    "        g, m = g_pad, m_pad\n",
    "\n",
    "    return g, m\n",
    "\n",
    "\n",
    "def glcm_feats(gray_img, roi_mask):\n",
    "    g, m = crop_to_roi_patch(gray_img, roi_mask, patch_size=GLCM_PATCH_SIZE)\n",
    "    if g is None:\n",
    "        return {f\"glcm_{p}\": np.nan for p in [\"contrast\",\"dissimilarity\",\"homogeneity\",\"energy\",\"correlation\",\"ASM\"]}\n",
    "\n",
    "    masked = g.copy()\n",
    "    masked[m == 0] = 0\n",
    "\n",
    "    # gray [0,1] değilse normalize\n",
    "    if masked.max() > 1.0:\n",
    "        masked = masked / 255.0\n",
    "\n",
    "    img_q = np.floor(np.clip(masked, 0, 1) * (GLCM_LEVELS - 1)).astype(np.uint8)\n",
    "\n",
    "    glcm = graycomatrix(\n",
    "        img_q,\n",
    "        distances=GLCM_DISTANCES,\n",
    "        angles=GLCM_ANGLES,\n",
    "        levels=GLCM_LEVELS,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    out = {}\n",
    "    for p in [\"contrast\",\"dissimilarity\",\"homogeneity\",\"energy\",\"correlation\",\"ASM\"]:\n",
    "        out[f\"glcm_{p}\"] = float(np.mean(graycoprops(glcm, p)))\n",
    "    return out\n",
    "\n",
    "\n",
    "rows = []\n",
    "skipped = 0\n",
    "\n",
    "print(\"✅ GLCM Parametreleri:\",\n",
    "      \"levels=\", GLCM_LEVELS,\n",
    "      \"distances=\", GLCM_DISTANCES,\n",
    "      \"angles=\", GLCM_ANGLES,\n",
    "      \"patch=\", GLCM_PATCH_SIZE)\n",
    "\n",
    "for p in tqdm(image_paths, desc=\"Feature extraction\", unit=\"image\"):\n",
    "    rgb = safe_imread(p)\n",
    "    if rgb is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    image_id = p.split(\"/\")[-1]\n",
    "\n",
    "    gray = preprocess_to_blur(rgb)\n",
    "\n",
    "    _, _, mask_otsu = otsu_mask_from_rgb(rgb)\n",
    "    mask_morph = morph_postprocess_safe(mask_otsu, ksize_close=5)\n",
    "    mask_final = pick_single_roi(mask_morph, min_area=MIN_AREA)\n",
    "\n",
    "    row = {\"image_id\": image_id, \"class\": \"unknown\"}\n",
    "    row.update(first_order_features(gray, mask_final))\n",
    "    row.update(shape_features(mask_final))\n",
    "    row.update(glcm_feats(gray, mask_final))\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"lesion_features.csv\", index=False)\n",
    "\n",
    "print(\"✅ Bitti.\")\n",
    "print(\"Toplam görüntü (liste):\", len(image_paths))\n",
    "print(\"İşlenen satır (ROI) sayısı:\", df.shape[0])\n",
    "print(\"Feature sütun sayısı:\", df.shape[1])\n",
    "print(\"Atlanan (okunamayan) dosya:\", skipped)\n",
    "print(\"CSV:\", \"lesion_features.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
